{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from itertools import combinations\n",
    "from pathlib import Path\n",
    "from gensim.models import Word2Vec\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reads csv file into a pandas dataframe\n",
    "articles = pd.read_csv(Path(\"data\") / \"articles.csv\")\n",
    "\n",
    "# Adds a new columns called node_id which corresponds to the index\n",
    "articles[\"node_id\"] = articles.index\n",
    "\n",
    "# Make List into an array\n",
    "articles[\"lists\"] = articles[\"lists\"].str.split(\"; \")\n",
    "\n",
    "### REMOVE THIS BEFORE SUBMISSION HERE I AM TAKING A SAMPLE\n",
    "#articles = articles.sample(n=10, random_state=42)\n",
    "test_data = pd.read_csv(Path(\"data\") / \"test_data.csv\")\n",
    "train_data = pd.read_csv(Path(\"data\") / \"train_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "medium_graph = nx.Graph()\n",
    "medium_graph.add_nodes_from(articles[\"node_id\"].to_list())\n",
    "\n",
    "list_to_nodes = defaultdict(set)\n",
    "for _, row in articles[[\"node_id\", \"lists\"]].iterrows():\n",
    "    for l in row[\"lists\"]:\n",
    "        list_to_nodes[l].add(row[\"node_id\"])\n",
    "\n",
    "for node_ids in list_to_nodes.values():\n",
    "    medium_graph.add_edges_from(combinations(node_ids, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us make the walks now to get the node embeddings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performing Random Walk\n",
    "def random_walks(graph: nx.Graph, num_walks: int, walk_length: int) -> np.ndarray:\n",
    "    result = []\n",
    "\n",
    "    for node in graph.nodes():\n",
    "        for i in range(num_walks):\n",
    "            walk = [node]\n",
    "            for j in range(walk_length - 1):\n",
    "                current_node = walk[-1]\n",
    "                neighbors_list = list(graph.neighbors(current_node))\n",
    "                \n",
    "                if len(neighbors_list) == 0:\n",
    "                    walk.append(node)\n",
    "                    continue        \n",
    "\n",
    "                # Randomly choose a neighbor\n",
    "                index = np.random.randint(len(neighbors_list))\n",
    "                next_node = neighbors_list[index]\n",
    "                walk.append(next_node)\n",
    "                \n",
    "             # Pad shorter walks with None as we want to create equal length np arrays   \n",
    "            if len(walk) < walk_length:\n",
    "                walk.extend([node] * (walk_length - len(walk)))\n",
    "            result.append(walk)\n",
    "\n",
    "    result = [[str(w) for w in walk] for walk in result]\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph with 27718 nodes and 2014162 edges\n"
     ]
    }
   ],
   "source": [
    "print(medium_graph)\n",
    "\n",
    "depth = 100\n",
    "walks = random_walks(medium_graph, num_walks= 5, walk_length = depth)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let us use the word2vec model to embed these walks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can take the context vector to be the mode at each index in the walk.\n",
    "\n",
    "model = Word2Vec(\n",
    "    walks,\n",
    "    vector_size=128,  # Dimensionality of the embeddings\n",
    "    window=5,         # Context window size\n",
    "    min_count=0,      # Ignore words with frequency below this\n",
    "    sg=1,             # Use skip-gram model\n",
    "    workers=4,        # Number of threads to use\n",
    "    epochs=10         # Number of iterations over the corpus\n",
    ")\n",
    "\n",
    "model.save(\"word2vec_model.model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cspace",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
